[schema]
# schema sql路径
fullpath = resources/spark/schema.sql
;fullpath = resources/PG/schema.sql
;fullpath = resources/CH/schema.sql
engine = spark
;engine =  PG
# RL-使用强化学习  greedy-使用贪心算法
;recommend_method = RL
recommend_method = greedy

[rawFile]
# mv 路径，若用于cost_estimation/update_model task，路径下应包含原始SQL及其执行计划
# 若用于join_candidate task，此路径为输出路径
mv_path = resources/spark/mv
query_path = resources/spark/
q_mv_path = resources/spark/
;mv_path = resources/PG/mv
;query_path = resources/PG/
;q_mv_path = resources/PG/q_mv
;mv_path = resources/CH/mv
;query_path = resources/CH/
;q_mv_path = resources/CH/q_mv
# 数据库名称和sql位置
database = tpcds_bin_partitioned_decimal_orc_40
;database = imdbload
tpcds_path = /home/tmp/tpcds/
increment_path = /home/tmp/incre/

# (1)query 执行的计划在yarn log的起止时间
q_log_start_time = 2022-10-19 19:32
q_log_end_time = 2022-10-19 21:32
# (2)query-mv 执行的计划在yarn log的起止时间，两者时间可以重叠，在代码中可以处理
q_mv_log_start_time = 2022-11-09 18:46
q_mv_log_end_time = 2022-11-09 19:22
# (3)增量sql的query
q_log_incre_start_time = 2023-01-06 09:57
q_log_incre_end_time = 2023-01-06 10:22
# (4)增量sql的query-mv
q_mv_log_incre_start_time = 2022-11-09 18:46
q_mv_log_incre_end_time = 2022-11-09 19:22

logparser_jar_path = /home/tmp/LogParser-1.0-SNAPSHOT.jar
cache_path = /home/tmp/CachePlugin-1.0-SNAPSHOT.jar
hdfs_input_path = hdfs://server1:9000/spark2-history
hdfs_output_path = hdfs://server1:9000/spark2-history-json
# ds文件
g_query_subs_path = ./resources/data/g_query_subs.ds
cnt_dict_path = ./resources/data/cnt_dict.ds
mv_bytes_dict_path = ./resources/data/mv_bytes_dict.ds

[csv]
# 以下三个均为recommend task的中间结果文件，即使用成本评估模型的结果
query_csv = ./resources/data/querydata.csv
mv_csv = ./resources/data/mvdata.csv
q_mv_csv = ./resources/data/query-mvdata.csv
# topN q-mv的对应关系
temp_q_mv_csv = ./resources/data/tmp_query-mvdata.csv
# recommend task的输出结果文件，包含了推荐的mv的编号和cost，根据编号可在上述mv_path中找到原始mv sql
recommend_mv_csv = ./resources/data/recommend-mvdata.csv
# 此次recommend后，淘汰的mv sql编号
remove_mv_csv = ./resources/data/remove-mvdata.csv
candidate_q_mv_csv = ./resources/data/candidate_query_mvdata.csv

[train]
# 训练数据的比例，不建议调整
train_rate = 0.8
# 训练batch大小，根据TOPN的N值大小进行调整，batch size取为2的整数次幂，取N/batch_size = 10左右，但是batch_size一般不超过256
batch_size = 8
# 训练轮数，根据N值大小进行调整，经验下在30~100之间调整，N=20时，epoch取30即可，N值较大时，适当加大epoch的值
epoch = 5
# 学习率，不建议调整
learning_rate = 0.005
# 以下均为深度学习网络参数，不建议调整
weight_decay = 1e-5
keyword_embedding_size = 32
char_embedding_size = 32
node_auxiliary_size = 2
first_hidden_size = 32
second_hidden_size = 32
drop_rate = 0.1
# 成本评估模型保存路径，切换数据库平台重新训练时请删除此文件
model_save_path_q = ./resources/ckpt_q.pt
model_save_path_q_mv = ./resources/ckpt_q_mv.pt
# 训练方式：深度学习（改写 + 空间） + 强化学习 or 深度学习（空间） + 贪心
# dqn
train_type = dqn

[rl]
# 推荐模型训练时batch大小，
batch_size_rl = 2
# 推荐模型训练时学习率
learning_rate_rl = 0.01
# 以下均为强化学习参数，不建议调整
epsilon = 0.9
gamma = 0.9
target_replace_iter = 3
memory_capacity = 10
drop_rate_rl = 0.2

[distributed]
# spark中的executor cores
num_processors = 21

[spark]
# spark资源管理器
spark_master = yarn
# spark python路径，即虚拟环境python路径
pyspark_python = /root/anaconda3/envs/hvd/bin/python
# drive 路径，同上
pyspark_drive_python = /root/anaconda3/envs/hvd/bin/python
# 以下均为spark参数
app_name = mview
spark_num_executors = 6
spark_executor_memory = 15g
spark_driver_memory = 5g

[mv_limit]
# 推荐的mv的数量限制
cnt_limit = 30
# 存储阈值，推荐时贪心算法使用,单位Mb
space_limit = 100
#单位s，低于该阈值的原始查询不做候选视图的选择
time_threshold = -1
# 单表projection的情况，如果project选中的列数超过原表的列数*col_threshold，则该组属性不做候选视图
col_threshold = 0.8
# 引用计数小于ref_threshold的子树，不拿来当候选视图。默认值为2
refer_threshold = 1

# 频繁项挖掘可配置表
[projection_list]
# 在单表projection时，如果配置了table_list,就只对table_list中的项做频繁项的挖掘
# 配置说明：表名之间用“,”隔开。如果列表为空，则所有表都需要处理
table_list = warehouse, store,
# table_list =
# True-使用projection False-不适用projection
use_projection = False
# 生成projection的最小数目
min_projection = 7

[mv_selection]
# 第一版，按照（1）覆盖的query（2）空间大小（3）参数
query_ratio = 0.5
space_ratio = 0.2
filter_ratio = 0.3
# 大小表的区别阀值，超过1G是大表，小于10M是小表
table_size_upper_bound = 50000000
table_size_lower_bound = 10485760
# 大小表的区分阀值，按照个数区分
table_size_big_bound = 6
table_size_small_bound = 11

[module_test]
sort_mv_test_csv = ./resources/data/sort_mv_test.csv
CH_IP = 90.90.61.118
CH_USER = default
CH_PASSWD = Streaming@123456
# True-开启视图优劣限制（可以达到极限） False-关闭
spark_cnt_limit_flag = True